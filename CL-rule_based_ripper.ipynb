{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit61209d9bcfea452998e2771b9ee1a7fb",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Ripper"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"dataset/CL_Normalized-dataset.csv\",sep='\\t',decimal=\",\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       Imax         E       PIL     MeanD     EDate  class\n",
       "0  0.009794  0.494960  0.167672  0.608219  0.366637      0\n",
       "1  0.005001  0.591952  0.167672  0.330594  0.634431      0\n",
       "2  0.004793  0.416542  0.167672  0.084932  0.000000      0\n",
       "3  0.014795  0.454229  0.167672  0.421918  0.430229      0\n",
       "4  0.009794  0.563574  0.167672  0.203836  0.645860      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Imax</th>\n      <th>E</th>\n      <th>PIL</th>\n      <th>MeanD</th>\n      <th>EDate</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.009794</td>\n      <td>0.494960</td>\n      <td>0.167672</td>\n      <td>0.608219</td>\n      <td>0.366637</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.005001</td>\n      <td>0.591952</td>\n      <td>0.167672</td>\n      <td>0.330594</td>\n      <td>0.634431</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.004793</td>\n      <td>0.416542</td>\n      <td>0.167672</td>\n      <td>0.084932</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014795</td>\n      <td>0.454229</td>\n      <td>0.167672</td>\n      <td>0.421918</td>\n      <td>0.430229</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.009794</td>\n      <td>0.563574</td>\n      <td>0.167672</td>\n      <td>0.203836</td>\n      <td>0.645860</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label = df.pop('class')\n",
    "train_set, test_set, train_label, test_label = train_test_split(df, label, stratify =label, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": []
  },
  {
   "source": [
    "## Grid Search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  30 out of  30 | elapsed:   31.2s finished\n",
      "Best parameters: {'k': 5, 'prune_size': 0.6}\n",
      "Best Score:  0.3347440354397187\n",
      "Complete Grid search:\n",
      "0.334 (+/-0.006) for {'k': 1, 'prune_size': 0.5}\n",
      "0.333 (+/-0.006) for {'k': 1, 'prune_size': 0.6}\n",
      "0.333 (+/-0.002) for {'k': 3, 'prune_size': 0.5}\n",
      "0.331 (+/-0.010) for {'k': 3, 'prune_size': 0.6}\n",
      "0.334 (+/-0.005) for {'k': 5, 'prune_size': 0.5}\n",
      "0.335 (+/-0.008) for {'k': 5, 'prune_size': 0.6}\n"
     ]
    }
   ],
   "source": [
    "import wittgenstein as lw\n",
    "ripper=lw.RIPPER()\n",
    "param_grid = {\"prune_size\": [0.5, 0.6], \"k\": [1, 3, 5]}\n",
    "grid_search = GridSearchCV(estimator=ripper, param_grid=param_grid, n_jobs=3,verbose=2,scoring='accuracy')\n",
    "grid_search.fit(train_set, train_label, class_feat='class',pos_class=1)\n",
    "\n",
    "print(\"Best parameters:\",grid_search.best_params_)\n",
    "print(\"Best Score: \",grid_search.best_score_)\n",
    "\n",
    "print(\"Complete Grid search:\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))"
   ]
  },
  {
   "source": [
    "## Modello finale"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wittgenstein as lw\n",
    "ripper = lw.RIPPER(k=1, prune_size=0.50)\n",
    "datas = pd.concat([train_set, train_label], axis=1)\n",
    "ripper.fit(datas, class_feat='class',pos_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Ruleset [E=0.38-0.44^MeanD=0.0-0.0^Imax=0.0-0.0]>"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "ripper.ruleset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy  0.6679815910585142\n",
      "Precision  1.0\n",
      "Recall  0.0039447731755424065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "print('Accuracy ', ripper.score(test_set, test_label))\n",
    "print('Precision ', ripper.score(test_set, test_label, precision_score))\n",
    "print('Recall ', ripper.score(test_set, test_label, recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], [], [], [], []])"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "ripper.predict(test_set[-15:], give_reasons=True)"
   ]
  }
 ]
}